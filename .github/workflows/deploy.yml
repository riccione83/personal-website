name: Deploy Website to S3 with Optimizations

on:
  push:
    branches: ["main", "master"]
  pull_request:
    branches: ["main", "master"]
  workflow_dispatch:

env:
  CLOUDFRONT_ENABLED: ${{ secrets.CLOUDFRONT_DISTRIBUTION_ID != '' }}

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Node.js
        uses: actions/setup-node@v3
        with:
          node-version: "18"
          cache: "yarn"

      - name: Install dependencies
        run: yarn install --frozen-lockfile

      - name: Build app with optimizations
        run: NODE_ENV=production yarn build
        env:
          # Ensure production environment for best optimization
          NODE_ENV: production

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION || 'us-east-1' }}

      - name: Set XML sitemap content type (direct upload)
        run: |
          # Upload sitemap.xml with proper content type
          aws s3 cp dist/sitemap.xml s3://${{ secrets.AWS_S3_BUCKET }}/sitemap.xml \
            --content-type "application/xml; charset=UTF-8" \
            --metadata-directive REPLACE \
            --cache-control "public, max-age=86400"
            
          # Upload compressed versions with proper content type and encoding
          if [ -f "dist/sitemap.xml.gz" ]; then
            aws s3 cp dist/sitemap.xml.gz s3://${{ secrets.AWS_S3_BUCKET }}/sitemap.xml.gz \
              --content-type "application/xml; charset=UTF-8" \
              --content-encoding "gzip" \
              --metadata-directive REPLACE \
              --cache-control "public, max-age=86400"
          fi

          if [ -f "dist/sitemap.xml.br" ]; then
            aws s3 cp dist/sitemap.xml.br s3://${{ secrets.AWS_S3_BUCKET }}/sitemap.xml.br \
              --content-type "application/xml; charset=UTF-8" \
              --content-encoding "br" \
              --metadata-directive REPLACE \
              --cache-control "public, max-age=86400"
          fi

          # Upload robots.txt with proper content type
          aws s3 cp dist/robots.txt s3://${{ secrets.AWS_S3_BUCKET }}/robots.txt \
            --content-type "text/plain; charset=UTF-8" \
            --metadata-directive REPLACE \
            --cache-control "public, max-age=86400"

      - name: Deploy regular files to S3
        run: |
          # Upload non-compressed assets first, excluding sitemap files which were already uploaded
          aws s3 sync dist/ s3://${{ secrets.AWS_S3_BUCKET }} \
            --delete \
            --exclude "*.gz" \
            --exclude "*.br" \
            --exclude "sitemap.xml" \
            --exclude "sitemap.xml.gz" \
            --exclude "sitemap.xml.br" \
            --exclude "robots.txt" \
            --cache-control "public, max-age=31536000, immutable" \
            --metadata-directive REPLACE

      - name: Set HTML specific content and cache settings
        run: |
          # Set HTML files with proper charset and shorter cache
          aws s3 cp s3://${{ secrets.AWS_S3_BUCKET }}/index.html s3://${{ secrets.AWS_S3_BUCKET }}/index.html \
            --content-type "text/html; charset=UTF-8" \
            --metadata-directive REPLACE \
            --cache-control "public, max-age=0, must-revalidate" \
            --website-redirect-location "https://${{ secrets.AWS_S3_BUCKET_DOMAIN || 'www.riccardorizzo.eu' }}/"
            
          # Set special HTML headers for iOS Safari compatibility
          aws s3 cp s3://${{ secrets.AWS_S3_BUCKET }}/index.html s3://${{ secrets.AWS_S3_BUCKET }}/index.html \
            --content-type "text/html; charset=UTF-8" \
            --metadata-directive REPLACE \
            --cache-control "public, max-age=0, must-revalidate" \
            --metadata '{"x-amz-meta-vary":"Accept-Encoding"}'

      - name: Upload compressed JS files
        run: |
          # Upload JS files with correct content-type and encoding
          find dist -name "*.js.gz" | while read file; do
            aws s3 cp "$file" s3://${{ secrets.AWS_S3_BUCKET }}/${file#dist/} \
              --content-type "application/javascript; charset=UTF-8" \
              --content-encoding "gzip" \
              --cache-control "public, max-age=31536000, immutable" \
              --metadata-directive REPLACE
          done

          # Upload Brotli compressed JS if available
          find dist -name "*.js.br" | while read file; do
            aws s3 cp "$file" s3://${{ secrets.AWS_S3_BUCKET }}/${file#dist/} \
              --content-type "application/javascript; charset=UTF-8" \
              --content-encoding "br" \
              --cache-control "public, max-age=31536000, immutable" \
              --metadata-directive REPLACE
          done

      - name: Upload compressed CSS files
        run: |
          # Upload CSS files with correct content-type and encoding
          find dist -name "*.css.gz" | while read file; do
            aws s3 cp "$file" s3://${{ secrets.AWS_S3_BUCKET }}/${file#dist/} \
              --content-type "text/css; charset=UTF-8" \
              --content-encoding "gzip" \
              --cache-control "public, max-age=31536000, immutable" \
              --metadata-directive REPLACE
          done

          # Upload Brotli compressed CSS if available
          find dist -name "*.css.br" | while read file; do
            aws s3 cp "$file" s3://${{ secrets.AWS_S3_BUCKET }}/${file#dist/} \
              --content-type "text/css; charset=UTF-8" \
              --content-encoding "br" \
              --cache-control "public, max-age=31536000, immutable" \
              --metadata-directive REPLACE
          done

      - name: Upload compressed HTML files
        run: |
          # Upload HTML files with correct content-type and encoding
          find dist -name "*.html.gz" | while read file; do
            aws s3 cp "$file" s3://${{ secrets.AWS_S3_BUCKET }}/${file#dist/} \
              --content-type "text/html; charset=UTF-8" \
              --content-encoding "gzip" \
              --cache-control "public, max-age=0, must-revalidate" \
              --metadata-directive REPLACE
          done

          # Upload Brotli compressed HTML if available
          find dist -name "*.html.br" | while read file; do
            aws s3 cp "$file" s3://${{ secrets.AWS_S3_BUCKET }}/${file#dist/} \
              --content-type "text/html; charset=UTF-8" \
              --content-encoding "br" \
              --cache-control "public, max-age=0, must-revalidate" \
              --metadata-directive REPLACE
          done

      - name: Set CORS configuration
        run: |
          aws s3api put-bucket-cors --bucket ${{ secrets.AWS_S3_BUCKET }} --cors-configuration '{
            "CORSRules": [
              {
                "AllowedOrigins": ["*"],
                "AllowedMethods": ["GET", "HEAD"],
                "AllowedHeaders": ["*"],
                "ExposeHeaders": ["ETag"],
                "MaxAgeSeconds": 86400
              }
            ]
          }'

      - name: Set Security Headers for CloudFront
        if: ${{ env.CLOUDFRONT_ENABLED == 'true' }}
        run: |
          # Create a security headers policy (only if using CloudFront)
          aws cloudfront create-response-headers-policy --cli-input-json '{
            "ResponseHeadersPolicyConfig": {
              "Name": "SecurityHeadersPolicy",
              "SecurityHeadersConfig": {
                "StrictTransportSecurity": {
                  "Override": true,
                  "TTL": 63072000
                },
                "ContentTypeOptions": {
                  "Override": true
                },
                "XSSProtection": {
                  "Override": true,
                  "Protection": true,
                  "ModeBlock": true
                },
                "ReferrerPolicy": {
                  "Override": true,
                  "ReferrerPolicy": "strict-origin-when-cross-origin"
                },
                "ContentSecurityPolicy": {
                  "Override": true,
                  "ContentSecurityPolicy": "default-src 'self'; img-src 'self' data: https://*; script-src 'self' 'unsafe-inline' 'unsafe-eval'; style-src 'self' 'unsafe-inline' https://fonts.googleapis.com; font-src 'self' https://fonts.gstatic.com; connect-src 'self'"
                },
                "FrameOptions": {
                  "Override": true,
                  "FrameOption": "DENY"
                }
              },
              "Comment": "Security headers for enhanced website security"
            }
          }' || echo "Could not create response headers policy (might already exist)"

      - name: Invalidate CloudFront cache
        # Only run this step if CLOUDFRONT_DISTRIBUTION_ID is available
        run: |
          if [ ! -z "${{ secrets.CLOUDFRONT_DISTRIBUTION_ID }}" ]; then
            aws cloudfront create-invalidation \
              --distribution-id ${{ secrets.CLOUDFRONT_DISTRIBUTION_ID }} \
              --paths "/*"
          else
            echo "CloudFront distribution ID not provided, skipping invalidation."
          fi
